"""
WikiSearchChain ì§ê´€ì ì¸ TDD í…ŒìŠ¤íŠ¸
ê° í…ŒìŠ¤íŠ¸ë§ˆë‹¤ ì„±ê³µ ë©”ì‹œì§€ ì¶œë ¥ìœ¼ë¡œ ì§„í–‰ìƒí™©ì„ ì‹¤ì‹œê°„ í™•ì¸

ì‹¤í–‰ ë°©ë²•:
    cd ai-service
    python tests/unit/chains/test_wiki_search_chain.py
    ë˜ëŠ”
    python -m pytest tests/unit/chains/test_wiki_search_chain.py -v -s
"""

import pytest
import sys
import os
import json
import time
from pathlib import Path
from unittest.mock import Mock, MagicMock, patch

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

# ì˜ì¡´ì„± ëª¨ë“ˆ Mock ì„¤ì •
mock_modules = ['utils', 'models', 'tools', 'chains', 'prompts']
for module_name in mock_modules:
    if module_name not in sys.modules:
        sys.modules[module_name] = Mock()

# í…ŒìŠ¤íŠ¸ ëŒ€ìƒ import
from app.chains.wiki_search_chain import WikiSearchChain

class TestWikiSearchChainBasics:
    """WikiSearchChain ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""

    def setup_method(self):
        """ê° í…ŒìŠ¤íŠ¸ ì „ì— ì‹¤í–‰ë˜ëŠ” ì„¤ì •"""
        self.mock_llm_client = Mock()
        self.chain = WikiSearchChain(llm_client=self.mock_llm_client)

        # Mock toolê³¼ prompt ì„¤ì •
        self.chain.tool = Mock()
        self.chain.prompt = Mock()

        # ê¸°ë³¸ ì„±ê³µ ì‘ë‹µ ì„¤ì •
        self.chain.tool.search_page.return_value = {
            'success': True,
            'title': 'í•œê°• (ì‘ê°€)',
            'summary': 'í•œê°•ì€ ëŒ€í•œë¯¼êµ­ì˜ ì†Œì„¤ê°€ì´ë‹¤.',
            'content': 'í•œê°•ì€ 1970ë…„ ê´‘ì£¼ì—ì„œ íƒœì–´ë‚¬ë‹¤. ì—°ì„¸ëŒ€í•™êµ êµ­ì–´êµ­ë¬¸í•™ê³¼ë¥¼ ì¡¸ì—…í–ˆë‹¤.',
            'url': 'https://ko.wikipedia.org/wiki/í•œê°•_(ì‘ê°€)'
        }

        self.chain.prompt.format_author_response.return_value = "í•œê°• ì‘ê°€ ì •ë³´ì…ë‹ˆë‹¤."

    def test_execute_fresh_search_flow_with_author_name(self):
        """ì‘ê°€ëª…ì´ í¬í•¨ëœ ì¿¼ë¦¬ì˜ ì‹ ê·œ ê²€ìƒ‰ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        query = "í•œê°• ì‘ê°€ì— ëŒ€í•´ ì•Œë ¤ì¤˜"
        context = {}

        print(f"  ğŸ” ì‹ ê·œ ê²€ìƒ‰ í”Œë¡œìš° í…ŒìŠ¤íŠ¸ - ì‘ê°€ëª… í¬í•¨")
        print(f"  ğŸ“ ì…ë ¥ ì¿¼ë¦¬: '{query}'")
        print(f"  ğŸ¯ ì˜ˆìƒ íë¦„: ì‹ ê·œ ê²€ìƒ‰ â†’ ì‘ê°€ ê²€ìƒ‰ ì²˜ë¦¬")

        # LLM ì˜ë„ ë¶„ì„ ëª¨í‚¹
        self.mock_llm_client.chat.completions.create.return_value = Mock(
            choices=[Mock(message=Mock(content=json.dumps({
                'intent_type': 'author_search',
                'extracted_keywords': ['í•œê°•'],
                'confidence': 0.9
            })))]
        )

        result = self.chain.execute(query, context)

        print(f"  ğŸ“Š ì‹¤í–‰ ê²°ê³¼:")
        print(f"    - ì•¡ì…˜: {result.get('action')}")
        print(f"    - ë©”ì‹œì§€ ê¸¸ì´: {len(result.get('message', ''))}")
        print(f"    - ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸: {bool(result.get('update_context'))}")
        print(f"  âœ… ê²€ìƒ‰ ë„êµ¬ í˜¸ì¶œë¨: {self.chain.tool.search_page.called}")
        print(f"  âœ… LLM í˜¸ì¶œë¨: {self.mock_llm_client.chat.completions.create.called}")

        assert result.get('action') in ['show_result', 'ask_clarification']
        assert 'message' in result
        assert 'update_context' in result
        assert self.chain.tool.search_page.called

        print("âœ… ì‘ê°€ëª… í¬í•¨ ì‹ ê·œ ê²€ìƒ‰ í”Œë¡œìš° í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_execute_context_question_flow(self):
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        query = "ê·¸ ì‘ê°€ ë‚˜ì´ëŠ”?"
        context = {
            'current_author': 'í•œê°•',
            'last_search_result': {
                'success': True,
                'title': 'í•œê°• (ì‘ê°€)',
                'content': 'í•œê°•ì€ 1970ë…„ 11ì›” 27ì¼ ê´‘ì£¼ì—ì„œ íƒœì–´ë‚¬ë‹¤.',
                'url': 'https://ko.wikipedia.org/wiki/í•œê°•_(ì‘ê°€)'
            }
        }

        print(f"  ğŸ’¬ ì»¨í…ìŠ¤íŠ¸ ì§ˆë¬¸ ì²˜ë¦¬ í”Œë¡œìš° í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì…ë ¥ ì¿¼ë¦¬: '{query}'")
        print(f"  ğŸ¯ ì»¨í…ìŠ¤íŠ¸: ì‘ê°€={context['current_author']}")
        print(f"  ğŸ¯ ì˜ˆìƒ íë¦„: ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš© â†’ íŠ¹ì • ì •ë³´ ì¶”ì¶œ")

        result = self.chain.execute(query, context)

        print(f"  ğŸ“Š ì‹¤í–‰ ê²°ê³¼:")
        print(f"    - ì•¡ì…˜: {result.get('action')}")
        print(f"    - ë©”ì‹œì§€ í¬í•¨ '1970': {'1970' in result.get('message', '')}")
        print(f"    - ì»¨í…ìŠ¤íŠ¸ ìœ ì§€: {result.get('update_context', {}).get('current_author') == 'í•œê°•'}")

        assert result.get('action') == 'show_result'
        assert '1970' in result.get('message', '') or 'ì¶œìƒ' in result.get('message', '')

        print("âœ… ì»¨í…ìŠ¤íŠ¸ ì§ˆë¬¸ ì²˜ë¦¬ í”Œë¡œìš° í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_execute_clarification_response_flow(self):
        """ëª…í™•í™” ì‘ë‹µ ì²˜ë¦¬ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        query = "ì±„ì‹ì£¼ì˜ì"
        context = {
            'waiting_for_clarification': True,
            'current_author': 'í•œê°•'
        }

        print(f"  ğŸ” ëª…í™•í™” ì‘ë‹µ ì²˜ë¦¬ í”Œë¡œìš° í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì…ë ¥ ì‘ë‹µ: '{query}'")
        print(f"  ğŸ¯ ìƒíƒœ: ëª…í™•í™” ëŒ€ê¸° ì¤‘")
        print(f"  ğŸ¯ ì˜ˆìƒ íë¦„: ëª…í™•í™” íŒŒì‹± â†’ ì¶”ê°€ ê²€ìƒ‰")

        # LLM ëª…í™•í™” íŒŒì‹± ëª¨í‚¹
        self.mock_llm_client.chat.completions.create.return_value = Mock(
            choices=[Mock(message=Mock(content=json.dumps({
                'book_title': 'ì±„ì‹ì£¼ì˜ì',
                'author_name': 'í•œê°•',
                'is_new_query': False
            })))]
        )

        result = self.chain.execute(query, context)

        print(f"  ğŸ“Š ì‹¤í–‰ ê²°ê³¼:")
        print(f"    - ì•¡ì…˜: {result.get('action')}")
        print(f"    - ëª…í™•í™” ì¢…ë£Œ: {not result.get('update_context', {}).get('waiting_for_clarification', True)}")
        print(f"    - ì‘ê°€ ì •ë³´ ì„¤ì •: {bool(result.get('update_context', {}).get('current_author'))}")

        assert result.get('action') in ['show_result', 'ask_clarification']
        assert 'message' in result

        print("âœ… ëª…í™•í™” ì‘ë‹µ ì²˜ë¦¬ í”Œë¡œìš° í…ŒìŠ¤íŠ¸ í†µê³¼")


class TestWikiSearchChainIntentAnalysis:
    """WikiSearchChain ì˜ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸"""

    def setup_method(self):
        """ê° í…ŒìŠ¤íŠ¸ ì „ì— ì‹¤í–‰ë˜ëŠ” ì„¤ì •"""
        self.mock_llm_client = Mock()
        self.chain = WikiSearchChain(llm_client=self.mock_llm_client)

    def test_analyze_query_intent_with_llm_success(self):
        """LLMì„ ì‚¬ìš©í•œ ì¿¼ë¦¬ ì˜ë„ ë¶„ì„ ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        query = "ê°œë¯¸ ì‘ê°€ ëˆ„êµ¬ì•¼"
        context = {}

        print(f"  ğŸ¤– LLM ì¿¼ë¦¬ ì˜ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì…ë ¥ ì¿¼ë¦¬: '{query}'")
        print(f"  ğŸ¯ ì˜ˆìƒ ì˜ë„: book_to_author")

        # LLM ì‘ë‹µ ëª¨í‚¹
        self.mock_llm_client.chat.completions.create.return_value = Mock(
            choices=[Mock(message=Mock(content=json.dumps({
                'intent_type': 'book_to_author',
                'extracted_keywords': ['ê°œë¯¸'],
                'confidence': 0.95
            })))]
        )

        result = self.chain._analyze_query_intent(query, context)

        print(f"  ğŸ“Š ë¶„ì„ ê²°ê³¼:")
        print(f"    - ì˜ë„ íƒ€ì…: {result.get('type')}")
        print(f"    - ì±… ì œëª©: {result.get('book_title')}")
        print(f"    - í‚¤ì›Œë“œ: {result.get('keywords')}")
        print(f"  âœ… LLM í˜¸ì¶œë¨: {self.mock_llm_client.chat.completions.create.called}")

        assert result.get('type') == 'book_to_author'
        assert result.get('book_title') == 'ê°œë¯¸'
        assert self.mock_llm_client.chat.completions.create.called

        print("âœ… LLM ì¿¼ë¦¬ ì˜ë„ ë¶„ì„ ì„±ê³µ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_analyze_query_intent_fallback(self):
        """LLM ì‹¤íŒ¨ì‹œ í´ë°± ì˜ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        query = "ê¹€ì˜í•˜ ì‘ê°€ ì •ë³´"
        context = {}

        print(f"  ğŸ”„ í´ë°± ì˜ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì…ë ¥ ì¿¼ë¦¬: '{query}'")
        print(f"  ğŸš¨ LLM ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜")

        # LLM ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜
        self.mock_llm_client.chat.completions.create.side_effect = Exception("API Error")

        result = self.chain._analyze_query_intent(query, context)

        print(f"  ğŸ“Š í´ë°± ë¶„ì„ ê²°ê³¼:")
        print(f"    - ì˜ë„ íƒ€ì…: {result.get('type')}")
        print(f"    - í‚¤ì›Œë“œ: {result.get('keywords')}")
        print(f"  âœ… í´ë°± ì„±ê³µ: {result.get('type') is not None}")

        assert result.get('type') in ['author_search', 'book_to_author']
        assert 'keywords' in result

        print("âœ… í´ë°± ì˜ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_fallback_analyze_intent_book_patterns(self):
        """í´ë°± ë°©ì‹ - ì±…â†’ì‘ê°€ íŒ¨í„´ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            ("ê°œë¯¸ ì‘ê°€ ëˆ„êµ¬ì•¼", "book_to_author", "ê°œë¯¸"),
            ("ì±„ì‹ì£¼ì˜ì ì“´ ì‚¬ëŒ", "book_to_author", "ì±„ì‹ì£¼ì˜ì"),
            ("í† ì§€ ì €ì ì•Œë ¤ì¤˜", "book_to_author", "í† ì§€"),
        ]

        print(f"  ğŸ“š ì±…â†’ì‘ê°€ íŒ¨í„´ ë¶„ì„ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(test_cases)}ê°œ")

        for i, (query, expected_type, expected_book) in enumerate(test_cases, 1):
            print(f"    {i}. ì¿¼ë¦¬: '{query}'")
            print(f"       ğŸ¯ ì˜ˆìƒ: {expected_type}, ì±…='{expected_book}'")

            result = self.chain._is_author_result(case)

            print(f"       ğŸ“Š íŒë³„ ê²°ê³¼: {result}")
            print(f"       âœ… ì‘ê°€ë¡œ ì¸ì‹: {result == True}")

            assert result == True
            print(f"       âœ… í…ŒìŠ¤íŠ¸ {i} í†µê³¼")

        print("âœ… ì‘ê°€ ê²°ê³¼ íŒë³„ - ê¸ì •ì  ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_is_author_result_negative_cases(self):
        """ì‘ê°€ ê²°ê³¼ íŒë³„ - ë¶€ì •ì  ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
        negative_cases = [
            {
                'success': True,
                'title': 'í•œê°•',
                'summary': 'í•œê°•ì€ ë‹¤ìŒ ì‚¬ëŒì„ ê°€ë¦¬í‚¨ë‹¤.',
                'content': 'ë™ëª…ì´ì¸...'
            },
            {
                'success': False,
                'title': '',
                'summary': '',
                'content': ''
            },
            {
                'success': True,
                'title': 'ì„œìš¸íŠ¹ë³„ì‹œ',
                'summary': 'ì„œìš¸íŠ¹ë³„ì‹œëŠ” ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì´ë‹¤.',
                'content': 'ì¸êµ¬ëŠ”...'
            }
        ]

        print(f"  âŒ ì‘ê°€ ê²°ê³¼ íŒë³„ - ë¶€ì •ì  ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(negative_cases)}ê°œ")

        for i, case in enumerate(negative_cases, 1):
            print(f"    {i}. ì œëª©: '{case['title']}'")
            print(f"       ìƒí™©: {'ì‹¤íŒ¨' if not case['success'] else 'ë™ëª…ì´ì¸' if 'ê°€ë¦¬í‚¨ë‹¤' in case['summary'] else 'ë¹„ê´€ë ¨'}")

            result = self.chain._is_author_result(case)

            print(f"       ğŸ“Š íŒë³„ ê²°ê³¼: {result}")
            print(f"       âœ… ì‘ê°€ ì•„ë‹˜ìœ¼ë¡œ ì¸ì‹: {result == False}")

            assert result == False
            print(f"       âœ… í…ŒìŠ¤íŠ¸ {i} í†µê³¼")

        print("âœ… ì‘ê°€ ê²°ê³¼ íŒë³„ - ë¶€ì •ì  ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_is_title_similar(self):
        """ì œëª© ìœ ì‚¬ë„ íŒë³„ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            ("ê°œë¯¸", "ê°œë¯¸ (ì†Œì„¤)", True),
            ("ì±„ì‹ì£¼ì˜ì", "ì±„ì‹ì£¼ì˜ì", True),
            ("í•œê°•", "í•œê°• (ì‘ê°€)", True),
            ("ê¹€ì˜í•˜", "ê¹€ì² ìˆ˜", False),
            ("ë¬´ë¼ì¹´ë¯¸í•˜ë£¨í‚¤", "ë¬´ë¼ì¹´ë¯¸ í•˜ë£¨í‚¤", True),
        ]

        print(f"  ğŸ” ì œëª© ìœ ì‚¬ë„ íŒë³„ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(test_cases)}ê°œ")

        for i, (query_title, result_title, expected) in enumerate(test_cases, 1):
            print(f"    {i}. ì¿¼ë¦¬: '{query_title}' vs ê²°ê³¼: '{result_title}'")
            print(f"       ì˜ˆìƒ: {expected}")

            result = self.chain._is_title_similar(query_title, result_title)

            print(f"       ğŸ“Š ìœ ì‚¬ë„ ê²°ê³¼: {result}")
            print(f"       âœ… ì •í™•ì„±: {result == expected}")

            assert result == expected
            print(f"       âœ… í…ŒìŠ¤íŠ¸ {i} í†µê³¼")

        print("âœ… ì œëª© ìœ ì‚¬ë„ íŒë³„ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_contains_author_name(self):
        """ì‘ê°€ëª… í¬í•¨ ì—¬ë¶€ íŒë³„ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            ("í•œê°• ì‘ê°€ ì •ë³´", True),
            ("ê¹€ì˜í•˜ì— ëŒ€í•´ ì•Œë ¤ì¤˜", True),
            ("ë¬´ë¼ì¹´ë¯¸ í•˜ë£¨í‚¤", True),
            ("ê·¸ ì‘ê°€ ë‚˜ì´ëŠ”?", False),
            ("ëŒ€í‘œì‘ì´ ë­ì•¼", False),
            ("J.K. ë¡¤ë§", True),
        ]

        print(f"  ğŸ‘¤ ì‘ê°€ëª… í¬í•¨ ì—¬ë¶€ íŒë³„ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(test_cases)}ê°œ")

        for i, (query, expected) in enumerate(test_cases, 1):
            print(f"    {i}. ì¿¼ë¦¬: '{query}' â†’ ì˜ˆìƒ: {expected}")

            result = self.chain._contains_author_name(query)

            print(f"       ğŸ“Š íŒë³„ ê²°ê³¼: {result}")
            print(f"       âœ… ì •í™•ì„±: {result == expected}")

            assert result == expected
            print(f"       âœ… í…ŒìŠ¤íŠ¸ {i} í†µê³¼")

        print("âœ… ì‘ê°€ëª… í¬í•¨ ì—¬ë¶€ íŒë³„ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_is_irrelevant_query(self):
        """ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ íŒë³„ í…ŒìŠ¤íŠ¸"""
        irrelevant_queries = [
            "ì•ˆë…•í•˜ì„¸ìš”",
            "ë‚ ì”¨ê°€ ì–´ë•Œ",
            "ã…‹ã…‹ã…‹ ì›ƒê²¨",
            "ë­í•´",
            "ê³ ë§ˆì›Œ",
            "ì¢‹ì€ í•˜ë£¨",
        ]

        relevant_queries = [
            "í•œê°• ì‘ê°€ ì •ë³´",
            "ê°œë¯¸ ì“´ ì‚¬ëŒ",
            "ì¢‹ì€ ì±… ì¶”ì²œ",
            "ì‘ê°€ê°€ ëˆ„êµ¬ì•¼",
        ]

        print(f"  ğŸš« ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ íŒë³„ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“‹ ê´€ë ¨ ì—†ëŠ” ì¿¼ë¦¬: {len(irrelevant_queries)}ê°œ")
        print(f"  ğŸ“‹ ê´€ë ¨ ìˆëŠ” ì¿¼ë¦¬: {len(relevant_queries)}ê°œ")

        print(f"    ê´€ë ¨ ì—†ëŠ” ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸:")
        for i, query in enumerate(irrelevant_queries, 1):
            print(f"      {i}. '{query}'")
            result = self.chain._is_irrelevant_query(query)
            print(f"         ğŸ“Š ê²°ê³¼: {result} (ê´€ë ¨ ì—†ìŒ)")
            assert result == True
            print(f"         âœ… í…ŒìŠ¤íŠ¸ {i} í†µê³¼")

        print(f"    ê´€ë ¨ ìˆëŠ” ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸:")
        for i, query in enumerate(relevant_queries, 1):
            print(f"      {i}. '{query}'")
            result = self.chain._is_irrelevant_query(query)
            print(f"         ğŸ“Š ê²°ê³¼: {result} (ê´€ë ¨ ìˆìŒ)")
            assert result == False
            print(f"         âœ… í…ŒìŠ¤íŠ¸ {i} í†µê³¼")

        print("âœ… ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ íŒë³„ í…ŒìŠ¤íŠ¸ í†µê³¼")

class TestWikiSearchChainSearchHandlers:
    """WikiSearchChain ê²€ìƒ‰ í•¸ë“¤ëŸ¬ í…ŒìŠ¤íŠ¸"""

    def setup_method(self):
        """ê° í…ŒìŠ¤íŠ¸ ì „ì— ì‹¤í–‰ë˜ëŠ” ì„¤ì •"""
        self.mock_llm_client = Mock()
        self.chain = WikiSearchChain(llm_client=self.mock_llm_client)
        self.chain.tool = Mock()
        self.chain.prompt = Mock()

    def test_handle_author_search_query_success(self):
        """ì‘ê°€ ê²€ìƒ‰ ì¿¼ë¦¬ ì²˜ë¦¬ ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        query = "ê¹€ì˜í•˜ ì‘ê°€ì— ëŒ€í•´ ì•Œë ¤ì¤˜"
        author_name = "ê¹€ì˜í•˜"
        query_intent = {'type': 'author_search', 'keywords': ['ê¹€ì˜í•˜']}
        context = {}

        print(f"  ğŸ‘¤ ì‘ê°€ ê²€ìƒ‰ ì¿¼ë¦¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì¿¼ë¦¬: '{query}'")
        print(f"  ğŸ¯ ì‘ê°€ëª…: '{author_name}'")

        # ì„±ê³µì ì¸ ê²€ìƒ‰ ê²°ê³¼ ëª¨í‚¹
        self.chain.tool.search_page.return_value = {
            'success': True,
            'title': 'ê¹€ì˜í•˜ (ì‘ê°€)',
            'summary': 'ê¹€ì˜í•˜ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ì†Œì„¤ê°€ì´ë‹¤.',
            'content': 'ê¹€ì˜í•˜ëŠ” 1968ë…„ ê²½ê¸°ë„ì—ì„œ íƒœì–´ë‚¬ë‹¤.',
            'url': 'https://ko.wikipedia.org/wiki/ê¹€ì˜í•˜_(ì‘ê°€)'
        }

        # LLM ë‹µë³€ ìƒì„± ëª¨í‚¹
        self.mock_llm_client.chat.completions.create.return_value = Mock(
            choices=[Mock(message=Mock(content="ê¹€ì˜í•˜ëŠ” 1968ë…„ì— íƒœì–´ë‚œ ëŒ€í•œë¯¼êµ­ì˜ ì†Œì„¤ê°€ì…ë‹ˆë‹¤."))]
        )

        result = self.chain._handle_author_search_query(query, author_name, query_intent, context)

        print(f"  ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"    - ì•¡ì…˜: {result.get('action')}")
        print(f"    - ë©”ì‹œì§€ ì¡´ì¬: {bool(result.get('message'))}")
        print(f"    - ì‘ê°€ëª… ì„¤ì •: {result.get('update_context', {}).get('current_author')}")
        print(f"  âœ… ê²€ìƒ‰ ë„êµ¬ í˜¸ì¶œ: {self.chain.tool.search_page.called}")

        assert result.get('action') == 'show_result'
        assert result.get('message')
        assert result.get('update_context', {}).get('current_author') == 'ê¹€ì˜í•˜'

        print("âœ… ì‘ê°€ ê²€ìƒ‰ ì¿¼ë¦¬ ì²˜ë¦¬ ì„±ê³µ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_handle_author_search_query_disambiguation(self):
        """ì‘ê°€ ê²€ìƒ‰ - ë™ëª…ì´ì¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        query = "í•œê°• ì‘ê°€"
        author_name = "í•œê°•"
        query_intent = {'type': 'author_search', 'keywords': ['í•œê°•']}
        context = {}

        print(f"  ğŸ” ë™ëª…ì´ì¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì¿¼ë¦¬: '{query}'")
        print(f"  ğŸ¯ ìƒí™©: ë™ëª…ì´ì¸ ì¡´ì¬")

        # ë™ëª…ì´ì¸ í˜ì´ì§€ ëª¨í‚¹
        self.chain.tool.search_page.return_value = {
            'success': True,
            'title': 'í•œê°•',
            'summary': 'í•œê°•ì€ ë‹¤ìŒ ì‚¬ëŒì„ ê°€ë¦¬í‚¨ë‹¤.',
            'content': 'í•œê°• (ê°•), í•œê°• (ì‘ê°€)',
            'url': 'https://ko.wikipedia.org/wiki/í•œê°•'
        }

        self.chain.prompt.get_search_failure_message.return_value = "í•œê°•ì— ëŒ€í•œ ì—¬ëŸ¬ ì •ë³´ê°€ ìˆìŠµë‹ˆë‹¤."

        result = self.chain._handle_author_search_query(query, author_name, query_intent, context)

        print(f"  ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"    - ì•¡ì…˜: {result.get('action')}")
        print(f"    - ëª…í™•í™” ìš”ì²­: {result.get('action') == 'ask_clarification'}")
        print(f"    - ëŒ€ê¸° ìƒíƒœ ì„¤ì •: {result.get('update_context', {}).get('waiting_for_clarification')}")

        assert result.get('action') == 'ask_clarification'
        assert result.get('update_context', {}).get('waiting_for_clarification') == True
        assert result.get('update_context', {}).get('current_author') == author_name

        print("âœ… ë™ëª…ì´ì¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_handle_book_to_author_query_success(self):
        """ì±…â†’ì‘ê°€ ì¿¼ë¦¬ ì²˜ë¦¬ ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        book_title = "ê°œë¯¸"
        query_intent = {'type': 'book_to_author', 'book_title': 'ê°œë¯¸'}
        context = {}

        print(f"  ğŸ“– ì±…â†’ì‘ê°€ ì¿¼ë¦¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì±… ì œëª©: '{book_title}'")
        print(f"  ğŸ¯ ì˜ˆìƒ: ì‘ê°€ ì •ë³´ ì¶”ì¶œ")

        # ì±… ê²€ìƒ‰ ê²°ê³¼ ëª¨í‚¹
        self.chain.tool.search_page.return_value = {
            'success': True,
            'title': 'ê°œë¯¸ (ì†Œì„¤)',
            'summary': 'ê°œë¯¸ëŠ” ë² ë¥´ë‚˜ë¥´ ë² ë¥´ë² ë¥´ì˜ ì†Œì„¤ì´ë‹¤.',
            'content': 'ì´ ì†Œì„¤ì€ ë² ë¥´ë‚˜ë¥´ ë² ë¥´ë² ë¥´ê°€ 1991ë…„ì— ë°œí‘œí–ˆë‹¤.',
            'url': 'https://ko.wikipedia.org/wiki/ê°œë¯¸_(ì†Œì„¤)'
        }

        # LLM ì‘ê°€ ì¶”ì¶œ ëª¨í‚¹
        self.mock_llm_client.chat.completions.create.return_value = Mock(
            choices=[Mock(message=Mock(content="ë² ë¥´ë‚˜ë¥´ ë² ë¥´ë² ë¥´"))]
        )

        result = self.chain._handle_book_to_author_query(book_title, query_intent, context)

        print(f"  ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"    - ì•¡ì…˜: {result.get('action')}")
        print(f"    - ë©”ì‹œì§€ í¬í•¨ 'ë² ë¥´ë² ë¥´': {'ë² ë¥´ë² ë¥´' in result.get('message', '')}")
        print(f"    - ì‘ê°€ëª… ì¶”ì¶œ: {result.get('update_context', {}).get('current_author')}")

        assert result.get('action') == 'show_result'
        assert 'ë² ë¥´ë² ë¥´' in result.get('message', '') or 'ê°œë¯¸' in result.get('message', '')

        print("âœ… ì±…â†’ì‘ê°€ ì¿¼ë¦¬ ì²˜ë¦¬ ì„±ê³µ í…ŒìŠ¤íŠ¸ í†µê³¼")


class TestWikiSearchChainInformationExtraction:
    """WikiSearchChain ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""

    def setup_method(self):
        """ê° í…ŒìŠ¤íŠ¸ ì „ì— ì‹¤í–‰ë˜ëŠ” ì„¤ì •"""
        self.mock_llm_client = Mock()
        self.chain = WikiSearchChain(llm_client=self.mock_llm_client)

        # ìƒ˜í”Œ ê²€ìƒ‰ ê²°ê³¼
        self.sample_search_result = {
            'success': True,
            'title': 'í•œê°• (ì‘ê°€)',
            'summary': 'í•œê°•ì€ ëŒ€í•œë¯¼êµ­ì˜ ì†Œì„¤ê°€ì´ë‹¤.',
            'content': '''í•œê°•ì€ 1970ë…„ 11ì›” 27ì¼ ê´‘ì£¼ê´‘ì—­ì‹œì—ì„œ íƒœì–´ë‚¬ë‹¤. 
                         ì—°ì„¸ëŒ€í•™êµ êµ­ì–´êµ­ë¬¸í•™ê³¼ë¥¼ ì¡¸ì—…í–ˆë‹¤. 
                         ì•„ë²„ì§€ëŠ” ì†Œì„¤ê°€ í•œìŠ¹ì›ì´ë‹¤.
                         ëŒ€í‘œì‘ìœ¼ë¡œëŠ” ì±„ì‹ì£¼ì˜ì, ì†Œë…„ì´ ì˜¨ë‹¤ ë“±ì´ ìˆë‹¤.
                         2016ë…„ ë§¨ë¶€ì»¤ìƒì„ ìˆ˜ìƒí–ˆë‹¤.''',
            'url': 'https://ko.wikipedia.org/wiki/í•œê°•_(ì‘ê°€)'
        }

    def test_extract_specific_info_request_university(self):
        """íŠ¹ì • ì •ë³´ ìš”ì²­ ì¶”ì¶œ - ëŒ€í•™êµ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            ("í•œê°• ëŒ€í•™êµ ì–´ë””ì•¼", "university"),
            ("ê·¸ ì‘ê°€ ì–´ë”” ëŒ€í•™ ë‚˜ì™”ì–´", "university"),
            ("í•™êµ ì •ë³´ ì•Œë ¤ì¤˜", "university"),
            ("ì¶œì‹  ëŒ€í•™ ì–´ë””", "university"),
        ]

        print(f"  ğŸ“ ëŒ€í•™êµ ì •ë³´ ìš”ì²­ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(test_cases)}ê°œ")

        for i, (query, expected) in enumerate(test_cases, 1):
            print(f"    {i}. ì¿¼ë¦¬: '{query}'")

            result = self.chain._extract_specific_info_request(query)

            print(f"       ğŸ“Š ì¶”ì¶œ ê²°ê³¼: '{result}'")
            print(f"       âœ… ì •í™•ì„±: {result == expected}")

            assert result == expected
            print(f"       âœ… í…ŒìŠ¤íŠ¸ {i} í†µê³¼")

        print("âœ… ëŒ€í•™êµ ì •ë³´ ìš”ì²­ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_extract_specific_info_request_birth_death(self):
        """íŠ¹ì • ì •ë³´ ìš”ì²­ ì¶”ì¶œ - ì¶œìƒ/ì‚¬ë§ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            ("ì–¸ì œ íƒœì–´ë‚¬ì–´", "birth"),
            ("ì¶œìƒì¼ì´ ì–¸ì œì•¼", "birth"),
            ("ë‚˜ì´ê°€ ëª‡ì´ì•¼", "birth"),
            ("ì–¸ì œ ì£½ì—ˆì–´", "death"),
            ("ì‚¬ë§ì¼ ì•Œë ¤ì¤˜", "death"),
            ("ì–¸ì œ íƒœì–´ë‚˜ì„œ ì–¸ì œ ì£½ì—ˆì–´", "birth_death"),
        ]

        print(f"  ğŸ“… ì¶œìƒ/ì‚¬ë§ ì •ë³´ ìš”ì²­ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(test_cases)}ê°œ")

        for i, (query, expected) in enumerate(test_cases, 1):
            print(f"    {i}. ì¿¼ë¦¬: '{query}' â†’ ì˜ˆìƒ: '{expected}'")

            result = self.chain._extract_specific_info_request(query)

            print(f"       ğŸ“Š ì¶”ì¶œ ê²°ê³¼: '{result}'")
            print(f"       âœ… ì •í™•ì„±: {result == expected}")

            assert result == expected
            print(f"       âœ… í…ŒìŠ¤íŠ¸ {i} í†µê³¼")

        print("âœ… ì¶œìƒ/ì‚¬ë§ ì •ë³´ ìš”ì²­ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_extract_specific_answer_university(self):
        """íŠ¹ì • ë‹µë³€ ì¶”ì¶œ - ëŒ€í•™êµ ì •ë³´ í…ŒìŠ¤íŠ¸"""
        info_type = "university"
        author_name = "í•œê°•"

        print(f"  ğŸ“ ëŒ€í•™êµ ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì‘ê°€: {author_name}")
        print(f"  ğŸ“Š ì¶”ì¶œ ëŒ€ìƒ: ì—°ì„¸ëŒ€í•™êµ")

        result = self.chain._extract_specific_answer(
            self.sample_search_result,
            info_type,
            author_name
        )

        print(f"  ğŸ“Š ì¶”ì¶œ ê²°ê³¼:")
        print(f"    - ë©”ì‹œì§€ ê¸¸ì´: {len(result)}")
        print(f"    - 'ì—°ì„¸ëŒ€í•™êµ' í¬í•¨: {'ì—°ì„¸ëŒ€í•™êµ' in result}")
        print(f"    - 'ì¡¸ì—…' í¬í•¨: {'ì¡¸ì—…' in result}")
        print(f"    - URL í¬í•¨: {'http' in result}")

        assert 'ì—°ì„¸ëŒ€í•™êµ' in result
        assert 'ì¡¸ì—…' in result
        assert 'http' in result

        print("âœ… ëŒ€í•™êµ ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_extract_specific_answer_birth(self):
        """íŠ¹ì • ë‹µë³€ ì¶”ì¶œ - ì¶œìƒ ì •ë³´ í…ŒìŠ¤íŠ¸"""
        info_type = "birth"
        author_name = "í•œê°•"

        print(f"  ğŸ‘¶ ì¶œìƒ ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì‘ê°€: {author_name}")
        print(f"  ğŸ“Š ì¶”ì¶œ ëŒ€ìƒ: 1970ë…„ 11ì›” 27ì¼")

        result = self.chain._extract_specific_answer(
            self.sample_search_result,
            info_type,
            author_name
        )

        print(f"  ğŸ“Š ì¶”ì¶œ ê²°ê³¼:")
        print(f"    - ë©”ì‹œì§€ ê¸¸ì´: {len(result)}")
        print(f"    - '1970' í¬í•¨: {'1970' in result}")
        print(f"    - 'íƒœì–´ë‚¬ìŠµë‹ˆë‹¤' í¬í•¨: {'íƒœì–´ë‚¬ìŠµë‹ˆë‹¤' in result}")

        assert '1970' in result
        assert 'íƒœì–´ë‚¬ìŠµë‹ˆë‹¤' in result or 'íƒœì–´ë‚˜' in result

        print("âœ… ì¶œìƒ ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_extract_specific_answer_family(self):
        """íŠ¹ì • ë‹µë³€ ì¶”ì¶œ - ê°€ì¡± ì •ë³´ í…ŒìŠ¤íŠ¸"""
        info_type = "family"
        author_name = "í•œê°•"

        print(f"  ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ê°€ì¡± ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì‘ê°€: {author_name}")
        print(f"  ğŸ“Š ì¶”ì¶œ ëŒ€ìƒ: ì•„ë²„ì§€ í•œìŠ¹ì›")

        # WikiInformationExtractor.find_enhanced_family_info ëª¨í‚¹
        with patch('app.chains.wiki_search_chain.WikiInformationExtractor') as mock_extractor:
            mock_extractor.find_enhanced_family_info.return_value = {
                'father': 'í•œìŠ¹ì›',
                'mother': None,
                'siblings': [],
                'family': []
            }

            result = self.chain._extract_specific_answer(
                self.sample_search_result,
                info_type,
                author_name
            )

        print(f"  ğŸ“Š ì¶”ì¶œ ê²°ê³¼:")
        print(f"    - ë©”ì‹œì§€ ê¸¸ì´: {len(result)}")
        print(f"    - 'í•œìŠ¹ì›' í¬í•¨: {'í•œìŠ¹ì›' in result}")
        print(f"    - 'ì•„ë²„ì§€' í¬í•¨: {'ì•„ë²„ì§€' in result}")

        assert 'í•œìŠ¹ì›' in result
        assert 'ì•„ë²„ì§€' in result

        print("âœ… ê°€ì¡± ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ í†µê³¼")


class TestWikiSearchChainHelperMethods:
    """WikiSearchChain í—¬í¼ ë©”ì„œë“œ í…ŒìŠ¤íŠ¸"""

    def setup_method(self):
        """ê° í…ŒìŠ¤íŠ¸ ì „ì— ì‹¤í–‰ë˜ëŠ” ì„¤ì •"""
        self.chain = WikiSearchChain()

    def test_is_author_result_positive_cases(self):
        """ì‘ê°€ ê²°ê³¼ íŒë³„ - ê¸ì •ì  ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
        positive_cases = [
            {
                'success': True,
                'title': 'ê¹€ì˜í•˜ (ì‘ê°€)',
                'summary': 'ê¹€ì˜í•˜ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ì†Œì„¤ê°€ì´ë‹¤.',
                'content': 'ì£¼ìš” ì‘í’ˆìœ¼ë¡œëŠ”...'
            },
            {
                'success': True,
                'title': 'í•œê°•',
                'summary': 'í•œê°•ì€ ì‹œì¸ì´ì ì†Œì„¤ê°€ì´ë‹¤.',
                'content': 'ì‘í’ˆ í™œë™ì„...'
            },
            {
                'success': True,
                'title': 'ì´ë§ë…„',
                'summary': 'ì´ë§ë…„ì€ ë§Œí™”ê°€ì´ë‹¤.',
                'content': 'ì›¹íˆ°ì„...'
            }
        ]

        print(f"  âœ… ì‘ê°€ ê²°ê³¼ íŒë³„ - ê¸ì •ì  ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(positive_cases)}ê°œ")

        for i, case in enumerate(positive_cases, 1):
            print(f"    {i}. ì œëª©: '{case['title']}'")
            print(f"       ìš”ì•½: '{case['summary'][:30]}...'")

            result =self.chain._fallback_analyze_intent(query)

            print(f"       ğŸ“Š ê²°ê³¼: íƒ€ì…={result.get('type')}, ì±…={result.get('book_title')}")
            print(f"       âœ… ì •í™•ì„±: {result.get('type') == expected_type}")

            assert result.get('type') == expected_type
            if expected_book:
                assert expected_book in result.get('book_title', '')

            print(f"       âœ… í…ŒìŠ¤íŠ¸ {i} í†µê³¼")

            print("âœ… ì±…â†’ì‘ê°€ íŒ¨í„´ ë¶„ì„ í…ŒìŠ¤íŠ¸ í†µê³¼")


class TestWikiSearchChainComplexScenarios:
    """WikiSearchChain ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""

    def setup_method(self):
        """ê° í…ŒìŠ¤íŠ¸ ì „ì— ì‹¤í–‰ë˜ëŠ” ì„¤ì •"""
        self.mock_llm_client = Mock()
        self.chain = WikiSearchChain(llm_client=self.mock_llm_client)
        self.chain.tool = Mock()
        self.chain.prompt = Mock()

    def test_compound_query_handling(self):
        """ë³µí•© ì§ˆë¬¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        query = "ê¹€ì˜í•˜ì™€ í•œê°•ì— ëŒ€í•´ ê°ê° ì•Œë ¤ì¤˜"
        context = {}

        print(f"  ğŸ”— ë³µí•© ì§ˆë¬¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì¿¼ë¦¬: '{query}'")
        print(f"  ğŸ¯ ì˜ˆìƒ: ë‘ ì‘ê°€ ì •ë³´ ê°ê° ì²˜ë¦¬")

        # ë³µí•© ì§ˆë¬¸ ê°ì§€ ëª¨í‚¹
        with patch('app.chains.wiki_search_chain.WikiInformationExtractor') as mock_extractor:
            mock_extractor.detect_compound_query.return_value = {
                'is_compound': True,
                'subjects': ['ê¹€ì˜í•˜', 'í•œê°•']
            }

            # ê° ì‘ê°€ë³„ ê²€ìƒ‰ ê²°ê³¼ ëª¨í‚¹
            self.chain.tool.search_page.side_effect = [
                {
                    'success': True,
                    'title': 'ê¹€ì˜í•˜ (ì‘ê°€)',
                    'summary': 'ê¹€ì˜í•˜ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ì†Œì„¤ê°€ì´ë‹¤.',
                    'content': '1968ë…„ì— íƒœì–´ë‚¬ë‹¤.',
                    'url': 'https://ko.wikipedia.org/wiki/ê¹€ì˜í•˜_(ì‘ê°€)'
                },
                {
                    'success': True,
                    'title': 'í•œê°• (ì‘ê°€)',
                    'summary': 'í•œê°•ì€ ëŒ€í•œë¯¼êµ­ì˜ ì†Œì„¤ê°€ì´ë‹¤.',
                    'content': '1970ë…„ì— íƒœì–´ë‚¬ë‹¤.',
                    'url': 'https://ko.wikipedia.org/wiki/í•œê°•_(ì‘ê°€)'
                }
            ]

            # LLM ì‘ë‹µ ëª¨í‚¹
            self.mock_llm_client.chat.completions.create.return_value = Mock(
                choices=[Mock(message=Mock(content="ì‘ê°€ ì •ë³´ì…ë‹ˆë‹¤."))]
            )

            result = self.chain._handle_compound_query(query, context)

        print(f"  ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"    - ë³µí•© ì§ˆë¬¸ ì¸ì‹: {result is not None}")
        if result:
            print(f"    - ì•¡ì…˜: {result.get('action')}")
            print(f"    - ê¹€ì˜í•˜ í¬í•¨: {'ê¹€ì˜í•˜' in result.get('message', '')}")
            print(f"    - í•œê°• í¬í•¨: {'í•œê°•' in result.get('message', '')}")
            print(f"    - ë³µí•© ì¿¼ë¦¬ í‘œì‹œ: {result.get('update_context', {}).get('compound_query')}")

            assert result.get('action') == 'show_result'
            assert 'ê¹€ì˜í•˜' in result.get('message', '')
            assert 'í•œê°•' in result.get('message', '')

        print("âœ… ë³µí•© ì§ˆë¬¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_context_priority_check(self):
        """ì»¨í…ìŠ¤íŠ¸ ìš°ì„ ìˆœìœ„ í™•ì¸ í…ŒìŠ¤íŠ¸"""
        test_scenarios = [
            {
                'query': 'ê·¸ ì‘ê°€ ë‚˜ì´ëŠ”?',
                'context': {'current_author': 'í•œê°•'},
                'expected': True,
                'description': 'ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ + í˜„ì¬ ì‘ê°€ ì¡´ì¬'
            },
            {
                'query': 'ê¹€ì˜í•˜ ì‘ê°€ ì •ë³´',
                'context': {'current_author': 'í•œê°•'},
                'expected': False,
                'description': 'ìƒˆë¡œìš´ ì‘ê°€ëª… ì–¸ê¸‰'
            },
            {
                'query': 'ì•ˆë…•í•˜ì„¸ìš”',
                'context': {'current_author': 'í•œê°•'},
                'expected': False,
                'description': 'ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸'
            }
        ]

        print(f"  ğŸ¯ ì»¨í…ìŠ¤íŠ¸ ìš°ì„ ìˆœìœ„ í™•ì¸ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤: {len(test_scenarios)}ê°œ")

        for i, scenario in enumerate(test_scenarios, 1):
            print(f"    {i}. {scenario['description']}")
            print(f"       ì¿¼ë¦¬: '{scenario['query']}'")
            print(f"       ì»¨í…ìŠ¤íŠ¸: {scenario['context']}")

            result = self.chain._check_context_priority(scenario['query'], scenario['context'])

            print(f"       ğŸ“Š ê²°ê³¼: ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©={result['should_use_context']}")
            print(f"       ì´ìœ : {result['reasoning']}")
            print(f"       âœ… ì˜ˆìƒê³¼ ì¼ì¹˜: {result['should_use_context'] == scenario['expected']}")

            assert result['should_use_context'] == scenario['expected']
            print(f"       âœ… ì‹œë‚˜ë¦¬ì˜¤ {i} í†µê³¼")

        print("âœ… ì»¨í…ìŠ¤íŠ¸ ìš°ì„ ìˆœìœ„ í™•ì¸ í…ŒìŠ¤íŠ¸ í†µê³¼")


class TestWikiSearchChainPerformance:
    """WikiSearchChain ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""

    def setup_method(self):
        """ê° í…ŒìŠ¤íŠ¸ ì „ì— ì‹¤í–‰ë˜ëŠ” ì„¤ì •"""
        self.chain = WikiSearchChain()
        self.chain.tool = Mock()
        self.chain.prompt = Mock()

        # ê¸°ë³¸ ì„±ê³µ ì‘ë‹µ ì„¤ì •
        self.chain.tool.search_page.return_value = {
            'success': True,
            'title': 'í…ŒìŠ¤íŠ¸ ì‘ê°€',
            'summary': 'í…ŒìŠ¤íŠ¸ ì‘ê°€ì…ë‹ˆë‹¤.',
            'content': 'í…ŒìŠ¤íŠ¸ ë‚´ìš©ì…ë‹ˆë‹¤.',
            'url': 'https://test.com'
        }

    def test_multiple_queries_performance(self):
        """ë‹¤ì¤‘ ì¿¼ë¦¬ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        queries = [
                      "í•œê°• ì‘ê°€ ì •ë³´",
                      "ê¹€ì˜í•˜ì— ëŒ€í•´ ì•Œë ¤ì¤˜",
                      "ë¬´ë¼ì¹´ë¯¸ í•˜ë£¨í‚¤",
                      "ê°œë¯¸ ì‘ê°€ ëˆ„êµ¬ì•¼",
                      "ì±„ì‹ì£¼ì˜ì ì“´ ì‚¬ëŒ"
                  ] * 20  # 100ê°œ ì¿¼ë¦¬

        print(f"  âš¡ ë‹¤ì¤‘ ì¿¼ë¦¬ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        print(f"    - í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ìˆ˜: {len(queries)}ê°œ")
        print(f"    - ëª©í‘œ ì‹œê°„: 10ì´ˆ ì´ë‚´")

        start_time = time.time()

        results = []
        for i, query in enumerate(queries):
            try:
                # ê¸°ë³¸ ë¶„ì„ë§Œ ìˆ˜í–‰ (ì‹¤ì œ ê²€ìƒ‰ì€ ëª¨í‚¹ë¨)
                intent = self.chain._analyze_query_intent(query)
                results.append(intent)

                if (i + 1) % 25 == 0:
                    elapsed = time.time() - start_time
                    print(f"      ğŸ’¾ ì§„í–‰: {i + 1}ê°œ ì²˜ë¦¬ ì™„ë£Œ ({elapsed:.2f}ì´ˆ)")

            except Exception as e:
                print(f"      âš ï¸ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {query} - {e}")
                results.append({'error': str(e)})

        end_time = time.time()
        total_time = end_time - start_time

        print(f"    ğŸ“Š ì„±ëŠ¥ ê²°ê³¼:")
        print(f"      - ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.4f}ì´ˆ")
        print(f"      - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_time/len(queries):.6f}ì´ˆ/ê°œ")
        print(f"      - ì´ˆë‹¹ ì²˜ë¦¬ëŸ‰: {len(queries)/total_time:.1f}ê°œ/ì´ˆ")
        print(f"      - ì„±ê³µë¥ : {len([r for r in results if 'error' not in r])}/{len(results)}")

        # ì„±ëŠ¥ ê²€ì¦
        assert total_time < 10.0
        assert len(results) == len(queries)

        print("âœ… ë‹¤ì¤‘ ì¿¼ë¦¬ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_memory_usage_stability(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸"""
        try:
            import psutil
        except ImportError:
            print("  âš ï¸ psutil ëª¨ë“ˆì´ ì—†ì–´ ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        print(f"  ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸")

        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss

        print(f"    - ì´ˆê¸° ë©”ëª¨ë¦¬: {initial_memory / 1024 / 1024:.2f}MB")

        # ëŒ€ëŸ‰ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        for i in range(500):
            query = f"í…ŒìŠ¤íŠ¸ ì‘ê°€ {i} ì •ë³´"
            context = {'test_iteration': i}

            # ì˜ë„ ë¶„ì„ë§Œ ìˆ˜í–‰
            try:
                self.chain._analyze_query_intent(query, context)
                self.chain._is_author_result({'success': True, 'title': f'ì‘ê°€{i}', 'summary': 'í…ŒìŠ¤íŠ¸'})
                self.chain._contains_author_name(query)
            except:
                pass

            if (i + 1) % 100 == 0:
                current_memory = process.memory_info().rss
                print(f"      ğŸ’½ {i + 1}íšŒ ì²˜ë¦¬ í›„: {current_memory / 1024 / 1024:.2f}MB")

        final_memory = process.memory_info().rss
        memory_increase = final_memory - initial_memory

        print(f"    ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê²°ê³¼:")
        print(f"      - ìµœì¢… ë©”ëª¨ë¦¬: {final_memory / 1024 / 1024:.2f}MB")
        print(f"      - ë©”ëª¨ë¦¬ ì¦ê°€: {memory_increase / 1024 / 1024:.2f}MB")
        print(f"      - ì¦ê°€ìœ¨: {(memory_increase / initial_memory) * 100:.2f}%")

        # ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ì´ 100MB ì´í•˜ì¸ì§€ í™•ì¸
        assert memory_increase < 100 * 1024 * 1024

        print("âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ í†µê³¼")


class TestWikiSearchChainErrorHandling:
    """WikiSearchChain ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""

    def setup_method(self):
        """ê° í…ŒìŠ¤íŠ¸ ì „ì— ì‹¤í–‰ë˜ëŠ” ì„¤ì •"""
        self.mock_llm_client = Mock()
        self.chain = WikiSearchChain(llm_client=self.mock_llm_client)
        self.chain.tool = Mock()
        self.chain.prompt = Mock()

    def test_search_tool_failure_handling(self):
        """ê²€ìƒ‰ ë„êµ¬ ì‹¤íŒ¨ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        query = "í•œê°• ì‘ê°€ ì •ë³´"
        context = {}

        print(f"  ğŸš¨ ê²€ìƒ‰ ë„êµ¬ ì‹¤íŒ¨ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì¿¼ë¦¬: '{query}'")
        print(f"  ğŸ¯ ìƒí™©: ê²€ìƒ‰ ë„êµ¬ ì‹¤íŒ¨")

        # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜
        self.chain.tool.search_page.return_value = {
            'success': False,
            'error': 'Network error'
        }

        # LLM ì˜ë„ ë¶„ì„ì€ ì„±ê³µ
        self.mock_llm_client.chat.completions.create.return_value = Mock(
            choices=[Mock(message=Mock(content=json.dumps({
                'intent_type': 'author_search',
                'extracted_keywords': ['í•œê°•']
            })))]
        )

        self.chain.prompt.get_search_failure_message.return_value = "ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

        result = self.chain.execute(query, context)

        print(f"  ğŸ“Š ì˜¤ë¥˜ ì²˜ë¦¬ ê²°ê³¼:")
        print(f"    - ì•¡ì…˜: {result.get('action')}")
        print(f"    - ì˜¤ë¥˜ ë©”ì‹œì§€ ì¡´ì¬: {bool(result.get('message'))}")
        print(f"    - ëª…í™•í™” ìš”ì²­: {result.get('action') == 'ask_clarification'}")

        assert result.get('action') in ['ask_clarification', 'error']
        assert result.get('message')

        print("âœ… ê²€ìƒ‰ ë„êµ¬ ì‹¤íŒ¨ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_llm_client_none_fallback(self):
        """LLM í´ë¼ì´ì–¸íŠ¸ ì—†ì„ ë•Œ í´ë°± í…ŒìŠ¤íŠ¸"""
        query = "ê¹€ì˜í•˜ ì‘ê°€ ì •ë³´"
        context = {}

        print(f"  ğŸ¤– LLM ì—†ì„ ë•Œ í´ë°± í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì¿¼ë¦¬: '{query}'")
        print(f"  ğŸ¯ ìƒí™©: LLM í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ")

        # LLM ì—†ëŠ” ì²´ì¸ ìƒì„±
        chain_no_llm = WikiSearchChain(llm_client=None)
        chain_no_llm.tool = Mock()
        chain_no_llm.prompt = Mock()

        # ê²€ìƒ‰ ì„±ê³µ ì‘ë‹µ ì„¤ì •
        chain_no_llm.tool.search_page.return_value = {
            'success': True,
            'title': 'ê¹€ì˜í•˜ (ì‘ê°€)',
            'summary': 'ê¹€ì˜í•˜ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ì†Œì„¤ê°€ì´ë‹¤.',
            'content': '1968ë…„ì— íƒœì–´ë‚¬ë‹¤.',
            'url': 'https://ko.wikipedia.org/wiki/ê¹€ì˜í•˜_(ì‘ê°€)'
        }

        chain_no_llm.prompt.format_author_response.return_value = "ê¹€ì˜í•˜ ì‘ê°€ ì •ë³´ì…ë‹ˆë‹¤."

        result = chain_no_llm.execute(query, context)

        print(f"  ğŸ“Š í´ë°± ì²˜ë¦¬ ê²°ê³¼:")
        print(f"    - ì•¡ì…˜: {result.get('action')}")
        print(f"    - ë©”ì‹œì§€ ì¡´ì¬: {bool(result.get('message'))}")
        print(f"    - í´ë°± ì„±ê³µ: {result.get('action') in ['show_result', 'ask_clarification']}")

        assert result.get('action') in ['show_result', 'ask_clarification', 'error']
        assert result.get('message')

        print("âœ… LLM ì—†ì„ ë•Œ í´ë°± í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_malformed_json_handling(self):
        """ì˜ëª»ëœ JSON ì‘ë‹µ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        query = "ê°œë¯¸ ì‘ê°€ ëˆ„êµ¬ì•¼"
        context = {}

        print(f"  ğŸ“ ì˜ëª»ëœ JSON ì‘ë‹µ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
        print(f"  ğŸ“ ì¿¼ë¦¬: '{query}'")
        print(f"  ğŸ¯ ìƒí™©: LLMì´ ì˜ëª»ëœ JSON ë°˜í™˜")

        # ì˜ëª»ëœ JSON ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜
        self.mock_llm_client.chat.completions.create.return_value = Mock(
            choices=[Mock(message=Mock(content="Invalid JSON response"))]
        )

        # ê²€ìƒ‰ ì„±ê³µ ì‘ë‹µ ì„¤ì • (í´ë°±ìš©)
        self.chain.tool.search_page.return_value = {
            'success': True,
            'title': 'ê°œë¯¸ (ì†Œì„¤)',
            'summary': 'ê°œë¯¸ëŠ” ë² ë¥´ë‚˜ë¥´ ë² ë¥´ë² ë¥´ì˜ ì†Œì„¤ì´ë‹¤.',
            'content': '1991ë…„ì— ë°œí‘œë˜ì—ˆë‹¤.',
            'url': 'https://ko.wikipedia.org/wiki/ê°œë¯¸_(ì†Œì„¤)'
        }

        result = self.chain.execute(query, context)

        print(f"  ğŸ“Š JSON ì˜¤ë¥˜ ì²˜ë¦¬ ê²°ê³¼:")
        print(f"    - ì•¡ì…˜: {result.get('action')}")
        print(f"    - í´ë°± ì„±ê³µ: {result.get('action') in ['show_result', 'ask_clarification']}")
        print(f"    - ë©”ì‹œì§€ ì¡´ì¬: {bool(result.get('message'))}")

        # JSON íŒŒì‹± ì‹¤íŒ¨í•´ë„ í´ë°±ìœ¼ë¡œ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨
        assert result.get('action') in ['show_result', 'ask_clarification', 'error']
        assert result.get('message')

        print("âœ… ì˜ëª»ëœ JSON ì‘ë‹µ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ í†µê³¼")


if __name__ == "__main__":
    start_time = time.time()

    print("ğŸ§ª WikiSearchChain ì§ê´€ì ì¸ TDD í…ŒìŠ¤íŠ¸ ì‹œì‘\n")

    # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
    print("ğŸ“‹ ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ - ì‹¤í–‰ íë¦„ ë° ë¶„ê¸°")
    print("=" * 60)
    test_basics = TestWikiSearchChainBasics()
    test_basics.setup_method()
    test_basics.test_execute_fresh_search_flow_with_author_name()
    print()
    test_basics.test_execute_context_question_flow()
    print()
    test_basics.test_execute_clarification_response_flow()

    # ì˜ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸
    print("\nğŸ¤– ì˜ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸ - LLM ë° í´ë°± ë°©ì‹")
    print("=" * 60)
    test_intent = TestWikiSearchChainIntentAnalysis()
    test_intent.setup_method()
    test_intent.test_analyze_query_intent_with_llm_success()
    print()
    test_intent.test_analyze_query_intent_fallback()
    print()
    test_intent.test_fallback_analyze_intent_book_patterns()

    # ê²€ìƒ‰ í•¸ë“¤ëŸ¬ í…ŒìŠ¤íŠ¸
    print("\nğŸ” ê²€ìƒ‰ í•¸ë“¤ëŸ¬ í…ŒìŠ¤íŠ¸ - ì‘ê°€/ì±… ê²€ìƒ‰ ì²˜ë¦¬")
    print("=" * 60)
    test_handlers = TestWikiSearchChainSearchHandlers()
    test_handlers.setup_method()
    test_handlers.test_handle_author_search_query_success()
    print()
    test_handlers.test_handle_author_search_query_disambiguation()
    print()
    test_handlers.test_handle_book_to_author_query_success()

    # ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
    print("\nğŸ“Š ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ - íŠ¹ì • ì •ë³´ ì¶”ì¶œ ë° ë‹µë³€ ìƒì„±")
    print("=" * 60)
    test_extraction = TestWikiSearchChainInformationExtraction()
    test_extraction.setup_method()
    test_extraction.test_extract_specific_info_request_university()
    print()
    test_extraction.test_extract_specific_info_request_birth_death()
    print()
    test_extraction.test_extract_specific_answer_university()
    print()
    test_extraction.test_extract_specific_answer_birth()
    print()
    test_extraction.test_extract_specific_answer_family()

    # í—¬í¼ ë©”ì„œë“œ í…ŒìŠ¤íŠ¸
    print("\nğŸ› ï¸ í—¬í¼ ë©”ì„œë“œ í…ŒìŠ¤íŠ¸ - íŒë³„ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜")
    print("=" * 60)
    test_helpers = TestWikiSearchChainHelperMethods()
    test_helpers.setup_method()
    test_helpers.test_is_author_result_positive_cases()
    print()
    test_helpers.test_is_author_result_negative_cases()
    print()
    test_helpers.test_is_title_similar()
    print()
    test_helpers.test_contains_author_name()
    print()
    test_helpers.test_is_irrelevant_query()

    # ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
    print("\nğŸ”— ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ - ë³µí•© ì§ˆë¬¸ ë° ì»¨í…ìŠ¤íŠ¸")
    print("=" * 60)
    test_complex = TestWikiSearchChainComplexScenarios()
    test_complex.setup_method()
    test_complex.test_compound_query_handling()
    print()
    test_complex.test_context_priority_check()

    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    print("\nâš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ - ì²˜ë¦¬ ì†ë„ ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±")
    print("=" * 60)
    test_performance = TestWikiSearchChainPerformance()
    test_performance.setup_method()
    test_performance.test_multiple_queries_performance()
    print()
    test_performance.test_memory_usage_stability()

    # ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    print("\nğŸš¨ ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ - ì˜ˆì™¸ ìƒí™© ëŒ€ì‘")
    print("=" * 60)
    test_errors = TestWikiSearchChainErrorHandling()
    test_errors.setup_method()
    test_errors.test_search_tool_failure_handling()
    print()
    test_errors.test_llm_client_none_fallback()
    print()
    test_errors.test_malformed_json_handling()

    end_time = time.time()
    total_time = end_time - start_time

    print("\n" + "=" * 60)
    print("ğŸ‰ ëª¨ë“  WikiSearchChain í…ŒìŠ¤íŠ¸ í†µê³¼!")
    print(f"â±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.2f}ì´ˆ")
    print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ìš”ì•½:")
    print("  âœ… ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°: 3ê°œ í…ŒìŠ¤íŠ¸")
    print("  âœ… ì˜ë„ ë¶„ì„: 3ê°œ í…ŒìŠ¤íŠ¸")
    print("  âœ… ê²€ìƒ‰ í•¸ë“¤ëŸ¬: 3ê°œ í…ŒìŠ¤íŠ¸")
    print("  âœ… ì •ë³´ ì¶”ì¶œ: 5ê°œ í…ŒìŠ¤íŠ¸")
    print("  âœ… í—¬í¼ ë©”ì„œë“œ: 5ê°œ í…ŒìŠ¤íŠ¸")
    print("  âœ… ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤: 2ê°œ í…ŒìŠ¤íŠ¸")
    print("  âœ… ì˜¤ë¥˜ ì²˜ë¦¬: 3ê°œ í…ŒìŠ¤íŠ¸")
    print(f"\nğŸ“ˆ ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: 26ê°œ")
    print("\nğŸ“ pytestë¡œ ì‹¤í–‰í•˜ë ¤ë©´:")
    print("    cd ai-service")
    print("    python -m pytest tests/unit/chains/test_wiki_search_chain.py -v -s")
    print("\nğŸš€ ê°œë³„ ì‹¤í–‰:")
    print("    python tests/unit/chains/test_wiki_search_chain.py")

