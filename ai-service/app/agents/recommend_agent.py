from langchain_core.prompts import PromptTemplate
from langchain_core.documents import Document
from dotenv import load_dotenv
import os
from config.llm import recommendation_llm, vectorstore
from prompts.recommend_prompt import recommend_prompt

# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

# ì¶”ì²œ ì‹¤í–‰ í•¨ìˆ˜
def run_recommend_agent(query_data: dict) -> str:
    emotion = query_data.get("emotion", "")
    genre = query_data.get("genre", "")
    keywords = query_data.get("keywords", [])
    keyword_str = ", ".join(keywords) if isinstance(keywords, list) else str(keywords)

    # ê²€ìƒ‰ ë¬¸ì¥ êµ¬ì„±
    search_query = f"{emotion} {genre} {keyword_str}".strip()
    #docs: list[Document] = vectorstore.similarity_search(search_query, k=3)

    # MMR ê¸°ë°˜ ë¦¬íŠ¸ë¦¬ë²„ ì‚¬ìš©
    retirever = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={"k": 3, "fetch_k":10, "lambda_mult": 0.7}
    )
    docs= retirever.invoke(search_query)

    if not docs:
        return "âŒ ê´€ë ¨ ë„ì„œë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”."

    # ë²¡í„° DBì—ì„œ ê²€ìƒ‰ëœ ë‚´ìš© ë¬¸ìì—´ë¡œ ë³€í™˜
    retrieved_docs = "\n\n".join([f"{i+1}. {doc.page_content}" for i, doc in enumerate(docs)])

    # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
    filled_prompt = recommend_prompt.format(
        emotion=emotion,
        genre=genre,
        keywords=keyword_str,
        retrieved_docs=retrieved_docs
    )

    # LLM í˜¸ì¶œ
    response = recommendation_llm.invoke(filled_prompt)

    return response.content


# í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    sample_query = {
        "emotion": "ìš°ìš¸",
        "genre": "ì—ì„¸ì´",
        "keywords": ["ìœ„ë¡œ", "ì‚¶", "í¬ë§"]
    }
    result = run_recommend_agent(sample_query)
    print("ğŸ“š ì¶”ì²œ ê²°ê³¼:\n", result)
