from humanfriendly.usage import render_usage
from langchain_core.prompts import PromptTemplate
from langchain_core.documents import Document
from dotenv import load_dotenv
import os
from config.llm import recommendation_llm, vectorstore
from prompts.recommend_prompt import recommend_prompt
from tools.emotion_tool import run_emotion_tool
from tools.genre_tool import run_genre_tool
from tools.author_tool import run_author_tool
from tools.hybrid_tool import run_hybrid_tool
# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()


# ì¶”ì²œ ì‹¤í–‰ í•¨ìˆ˜
def run_recommend_agent(query_data: dict) -> str:
    emotion = query_data.get("emotion", "")
    genre = query_data.get("genre", "")
    author = query_data.get("author", "")
    keywords = query_data.get("keywords", [])
    #keyword_str = ", ".join(keywords) if isinstance(keywords, list) else str(keywords)
    user_input = query_data.get("user_input", "")

    print(f"[DEBUG] emotion: '{emotion}', genre: '{genre}', author: '{author}', keywords: {keywords}")

    # author ì¡°ê±´ì´ ìˆì„ ê²½ìš° ê°€ì¥ ë¨¼ì € ì²˜ë¦¬
    if author:
        print("author_tool ì‚¬ìš©")
        return run_author_tool(author=author, user_input=user_input)

    # emotion ì¡°ê±´ë§Œ ìˆì„ ê²½ìš°
    if emotion and not genre and not keywords:
        print("emotion_tool ì‚¬ìš©")
        return run_emotion_tool(emotion=emotion, user_input=user_input)

    # genre ì¡°ê±´ë§Œ ìˆì„ ê²½ìš°
    if genre and not emotion and not keywords:
        print("genre_tool ì‚¬ìš©")
        return run_genre_tool(genre=genre, user_input=user_input)

    # ê·¸ ì™¸ emotion + genre ë“± ë³µí•© ì¡°ê±´ â†’ hybrid_tool
    has_multiple = sum([
        bool(emotion),
        bool(genre),
        bool(keywords)
    ]) >= 2

    if has_multiple:
        print("hybrid_tool ì‚¬ìš©")
        info = {
            "emotion": emotion,
            "genre": genre,
            "author": author,  # authorëŠ” ë³´í†µ ìœ„ì—ì„œ ë¹ ì§€ì§€ë§Œ, í¬í•¨í•´ë„ ë¬´ë°©
            "keywords": keywords,
            "user_input": user_input
        }
        return run_hybrid_tool(info)

    # âŒ ì•„ë¬´ ì¡°ê±´ë„ ì—†ì„ ë•Œ
    return "â—ì¶”ì²œì„ ìœ„í•´ ê°ì •, ì¥ë¥´, ì‘ê°€, í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤."
if __name__ == "__main__":
    # sample_query = {
    #     "emotion": "ìš°ìš¸",
    #     "genre": None,
    #     "keywords": [],
    #     "user_input": "ìš°ìš¸í•  ë•Œ ìœ„ë¡œê°€ ë˜ëŠ” ì±… ì¶”ì²œí•´ì¤˜"
    # }
    sample_query = {
        "emotion": "ì‚¬ë‘ìŠ¤ëŸ¬ìš´",
        "genre": "ì†Œì„¤",
        "author": "",
        "keywords": [],
        "user_input": "ì‚¬ë‘ìŠ¤ëŸ¬ìš´ ì†Œì„¤ ì¶”ì²œ"
    }
    print(run_recommend_agent(sample_query))


#     # ê²€ìƒ‰ ë¬¸ì¥ êµ¬ì„±
#     search_query = f"{emotion} {genre} {keyword_str}".strip()
#     #docs: list[Document] = vectorstore.similarity_search(search_query, k=3)
#
#     # MMR ê¸°ë°˜ ë¦¬íŠ¸ë¦¬ë²„ ì‚¬ìš©
#     retirever = vectorstore.as_retriever(
#         search_type="mmr",
#         search_kwargs={"k": 3, "fetch_k":10, "lambda_mult": 0.7}
#     )
#     docs= retirever.invoke(search_query)
#
#     if not docs:
#         return "âŒ ê´€ë ¨ ë„ì„œë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”."
#
#     # ë²¡í„° DBì—ì„œ ê²€ìƒ‰ëœ ë‚´ìš© ë¬¸ìì—´ë¡œ ë³€í™˜
#     retrieved_docs = "\n\n".join([f"{i+1}. {doc.page_content}" for i, doc in enumerate(docs)])
#
#     # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
#     filled_prompt = recommend_prompt.format(
#         emotion=emotion,
#         genre=genre,
#         keywords=keyword_str,
#         retrieved_docs=retrieved_docs
#     )
#
#     # LLM í˜¸ì¶œ
#     response = recommendation_llm.invoke(filled_prompt)
#
#     return response.content
#
#
# # í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰ ì½”ë“œ
# if __name__ == "__main__":
#     sample_query = {
#         "emotion": "ìš°ìš¸",
#         "genre": "ì—ì„¸ì´",
#         "keywords": ["ìœ„ë¡œ", "ì‚¶", "í¬ë§"]
#     }
#     result = run_recommend_agent(sample_query)
#     print("ğŸ“š ì¶”ì²œ ê²°ê³¼:\n", result)
