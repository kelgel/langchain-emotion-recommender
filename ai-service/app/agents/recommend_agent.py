from langchain_core.prompts import PromptTemplate
from config.llm import recommendation_llm, embedding_model
from langchain_chroma import Chroma

# # 1. ë²¡í„° DB ë¡œë“œ (Chroma)
# import os
#
# # __file__ ê¸°ì¤€ìœ¼ë¡œ ì ˆëŒ€ ê²½ë¡œ ìƒì„±
# CHROMA_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "data", "chroma_db"))
#
# db = Chroma(
#     persist_directory=CHROMA_PATH,
#     embedding_function=embedding_model
# )
#
# print(f"ğŸ“ Chroma ê²½ë¡œ: {CHROMA_PATH}")
# print("ğŸ“„ í¬í•¨ íŒŒì¼ë“¤:", os.listdir(CHROMA_PATH))


recommend_prompt = PromptTemplate(
    input_variables = ["emotion", "genre", "keywords"],
    template="""
    ë„ˆëŠ” ì„œì  ì‚¬ì´íŠ¸ì˜ ë„ì„œ ì¶”ì²œ AIì•¼.

    ì•„ë˜ ì •ë³´ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ê´€ë ¨ëœ ë„ì„œë¥¼ ìµœëŒ€ 3ê¶Œ ì¶”ì²œí•´ì¤˜:
    - ê°ì •: {emotion}
    - ì¥ë¥´: {genre}
    - í‚¤ì›Œë“œ: {keywords}
    
    ê°€ëŠ¥í•œ ì •ë³´ë§Œ í™œìš©í•´ì„œ ë„ì„œë¥¼ ì¶”ì²œí•´.
    ì¶”ì²œí•  ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ìœ ì‚¬ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ìœ ì¶”í•´ì„œ ì¶”ì²œí•´ë„ ë¼.
    """
)

def run_recommend_agent(query_data: dict) -> str:
    emotion = query_data.get("emotion")
    genre = query_data.get("genre")
    keywords = query_data.get("keywords", [])  # ë˜ëŠ” "" ë¡œ ì´ˆê¸°í™”
    keyword_str = ", ".join(keywords) if isinstance(keywords, list) else str(keywords)

    prompt = recommend_prompt.format(
        emotion=emotion,
        genre=genre,
        keywords=keyword_str
    )
    response = recommendation_llm.invoke(prompt)

    return response.content


