"""
main_agent.py
main_agent ë©”ì¸ ì—ì´ì „íŠ¸-ì¿¼ë¦¬ ë¼ìš°íŒ…
"""
from chromadb.app import app
from dotenv import load_dotenv

# import app.main_agent.intent_router.route_intent
# from chains import query_analysis_chain, intent_classify_chain
# from chains.clarification_chain import get_clarification_chain
# from utils.clarification_checker import needs_clarification
# from prompts.clarification_prompt import get_clarification_prompt
# from config.llm import clarification_llm
# from dotenv import load_dotenv


load_dotenv()

async def run_pipeline(user_input):
    while True:

        # 1. ì§ˆì˜ ë¶„ì„
        query = app.chains.query_analysis_chain.invoke({"user_input": user_input})
        print(f"ğŸ“Œ ë¶„ì„ ê²°ê³¼: {query}")

        # 2. í™”í–‰ ë¶„ë¥˜
        intent = app.chains.intent_classify_chain.invoke({"user_input": user_input})
        print(f"ğŸ“Œ ë¶„ë¥˜ëœ ì˜ë„: {intent}")

        # 3. í•„ìˆ˜ ì •ë³´ ëˆ„ë½ ì‹œ clarification loop
        while app.utils.needs_clarification(intent, query):
            # [1] í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
            prompt = app.prompts.get_clarification_prompt(intent)
            prompt_string = prompt.format(**query)

            # [2] LLM ì‹¤í–‰ â†’ ìì—°ì–´ ë©”ì‹œì§€
            llm_response = app.config.llm.clarification_llm.invoke(prompt_string)
            print(f"â“ ì¶”ê°€ ì§ˆë¬¸: {llm_response.content}")  # ì—¬ê¸´ ìì—°ì–´ ì¶œë ¥

            user_input = input("â†©ï¸ ì‚¬ìš©ì ì‘ë‹µ: ")
            query = app.chains.query_analysis_chain.invoke({"user_input": user_input})
            print(f"ğŸ“Œ ì¬ë¶„ì„ ê²°ê³¼: {query}")

        # 4. ìµœì¢… intent ì²˜ë¦¬
        response = app.main_agent.intent_router.route_intent(intent, query)
        print(f"\nğŸ¤– ì±—ë´‡ ì‘ë‹µ:\n{response}")
        break

if __name__ == "__main__":
    run_pipeline()