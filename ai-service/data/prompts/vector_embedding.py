# vector_embedding_enhanced.py - ìƒ˜í”Œ ë°ì´í„° ê¸°ë°˜ í–¥ìƒëœ ë²¡í„° ì„ë² ë”©
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.schema import Document
import mysql.connector
import json
import os
from datetime import datetime
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
openai_key = os.getenv("OPENAI_API_KEY")
if not openai_key:
    raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

def load_db_config_from_properties():
    """application.propertiesì—ì„œ DB ì„¤ì • ì½ê¸°"""
    # í˜„ì¬ íŒŒì¼ì—ì„œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)  # 1ë‹¨ê³„ ìœ„ë¡œ
    properties_path = os.path.join(project_root, 'src', 'main', 'resources', 'application.properties')
    
    print(f"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
    print(f"Properties íŒŒì¼ ê²½ë¡œ: {properties_path}")
    print(f"Properties íŒŒì¼ ì¡´ì¬: {os.path.exists(properties_path)}")
    
    db_config = {
        'host': 'localhost',
        'port': 3306,
        'user': 'root',
        'password': '',
        'database': 'bookstore',
        'charset': 'utf8mb4',
        'autocommit': False,
        'use_unicode': True
    }
    
    try:
        with open(properties_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line.startswith('spring.datasource.url='):
                    # jdbc:mysql://host:port/database?params íŒŒì‹±
                    url = line.split('=', 1)[1]
                    if '://' in url and '/' in url:
                        # host:port ì¶”ì¶œ
                        host_part = url.split('://')[1].split('/')[0]
                        if ':' in host_part:
                            db_config['host'] = host_part.split(':')[0]
                            db_config['port'] = int(host_part.split(':')[1])
                        else:
                            db_config['host'] = host_part
                            db_config['port'] = 3306
                        
                        # database ì¶”ì¶œ
                        if '/' in url:
                            # jdbc:mysql://host:port/database?params
                            url_parts = url.split('/')
                            if len(url_parts) >= 4:
                                db_part = url_parts[3]  # database ë¶€ë¶„
                                if '?' in db_part:
                                    db_name = db_part.split('?')[0]
                                else:
                                    db_name = db_part
                                db_config['database'] = db_name
                            
                elif line.startswith('spring.datasource.username='):
                    db_config['user'] = line.split('=', 1)[1]
                elif line.startswith('spring.datasource.password='):
                    db_config['password'] = line.split('=', 1)[1]
        
        print(f"DB ì„¤ì • ë¡œë“œ ì™„ë£Œ: {db_config['user']}@{db_config['host']}:{db_config['port']}/{db_config['database']}")
        return db_config
        
    except Exception as e:
        print(f"application.properties ì½ê¸° ì‹¤íŒ¨: {e}")
        print(f"Properties íŒŒì¼ ê²½ë¡œ: {properties_path}")
        print(f"Properties íŒŒì¼ ì¡´ì¬: {os.path.exists(properties_path)}")
        print("ê¸°ë³¸ ì„¤ì • ì‚¬ìš© - AWS RDS ì„¤ì •")
        # AWS RDS ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
        db_config.update({
            'host': 'tp4team5.cny6cmeagio6.ap-northeast-2.rds.amazonaws.com',
            'user': 'admin',
            'password': 'corzmdls1!'
        })
        return db_config

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì • (application.propertiesì—ì„œ ìë™ ë¡œë“œ)
DB_CONFIG = load_db_config_from_properties()

# OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")

# Chroma ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •
PERSIST_DIRECTORY = "./chroma_db"
vectorstore = Chroma(
    collection_name="bookstore_collection",
    embedding_function=embeddings,
    persist_directory=PERSIST_DIRECTORY
)

def create_enhanced_product_review_documents():
    """í–¥ìƒëœ Product + Review í†µí•© ë¬¸ì„œ ìƒì„± (ìƒ˜í”Œ ë°ì´í„° ê¸°ë°˜)"""
    print("=== í–¥ìƒëœ Product + Review í†µí•© ë¬¸ì„œ ìƒì„± ì¤‘ ===")

    connection = mysql.connector.connect(**DB_CONFIG)
    cursor = connection.cursor()

    try:
        # 1. ë¦¬ë·°ê°€ ìˆëŠ” ìƒí’ˆë“¤: Product + Review ì¡°í•© ë¬¸ì„œ (ì‹¤ì œ í…ŒìŠ¤íŠ¸ëœ ì¿¼ë¦¬)
        cursor.execute("""
            SELECT p.isbn, tc.top_category_name, mc.mid_category_name, lc.low_category_name,
                   p.product_name, p.author, p.publisher, p.price, p.rate,
                   p.brief_description, p.detail_description,
                   p.emotion_keyword as product_emotion, p.product_keyword,
                   pr.review_title, pr.review_content, pr.emotion_keyword as review_emotion,
                   p.page, p.sales_status, p.reg_date
            FROM product p
                     JOIN product_review pr ON p.isbn = pr.isbn
                     LEFT JOIN low_category lc ON p.low_category = lc.low_category
                     LEFT JOIN middle_category mc ON lc.mid_category = mc.mid_category
                     LEFT JOIN top_category tc ON mc.top_category = tc.top_category
            WHERE p.emotion_keyword IS NOT NULL AND p.product_keyword IS NOT NULL
              AND pr.emotion_keyword IS NOT NULL
        """)

        product_review_pairs = cursor.fetchall()
        documents = []

        print(f"Product + Review ì¡°í•© ë¬¸ì„œ ìƒì„±: {len(product_review_pairs)}ê°œ")

        for row in product_review_pairs:
            (isbn, top_category_name, mid_category_name, low_category_name,
             name, author, publisher, price, rate,
             brief, detail,
             product_emotion_kw, product_kw,
             review_title, review_content, review_emotion_kw,
             page, sales_status, reg_date) = row

            # ìƒí’ˆ í‚¤ì›Œë“œ íŒŒì‹±
            product_emotion_keywords = json.loads(product_emotion_kw) if product_emotion_kw else []
            product_keywords = json.loads(product_kw) if product_kw else []
            review_emotion_keywords = json.loads(review_emotion_kw) if review_emotion_kw else []

            # ì™„ì „ ë™ê¸°í™”: page_contentì™€ metadata ì¼ì¹˜
            content = f"""
                ìƒìœ„ ì¹´í…Œê³ ë¦¬: {top_category_name or ''}
                ì¤‘ê°„ ì¹´í…Œê³ ë¦¬: {mid_category_name or ''}
                í•˜ìœ„ ì¹´í…Œê³ ë¦¬: {low_category_name or ''}
                ì œí’ˆëª…: {name}
                ì €ì: {author or ''}
                ì¶œíŒì‚¬: {publisher or ''}
                ê°€ê²©: {price or 0}ì›
                í‰ì : {rate or 0}ì 
                ê°„ë‹¨ ì„¤ëª…: {brief or ''}
                ìƒì„¸ ì„¤ëª…: {detail or ''}
                ìƒí’ˆ ê°ì •: {', '.join(product_emotion_keywords)}
                ìƒí’ˆ í‚¤ì›Œë“œ: {', '.join(product_keywords)}
                ë¦¬ë·° ì œëª©: {review_title or ''}
                ë¦¬ë·° ë‚´ìš©: {review_content or ''}
                ë¦¬ë·° ê°ì •: {', '.join(review_emotion_keywords)}
                í˜ì´ì§€: {page or 0}í˜ì´ì§€
                íŒë§¤ìƒíƒœ: {sales_status or ''}
                ë“±ë¡ì¼: {reg_date.strftime('%Y-%m-%d') if reg_date else ''}"""

            # ì™„ì „ ë™ê¸°í™”: metadataê°€ page_contentì™€ ì •í™•íˆ ì¼ì¹˜
            metadata = {
                "isbn": isbn,
                "type": "product_with_review",
                "top_category_name": top_category_name or "",
                "mid_category_name": mid_category_name or "",
                "low_category_name": low_category_name or "",
                "product_name": name,
                "author": author or "",
                "publisher": publisher or "",
                "price": int(price) if price else 0,
                "rate": float(rate) if rate else 0.0,
                "brief_description": brief or "",
                "detail_description": detail or "",
                "product_emotion_keywords": product_emotion_kw or "",
                "product_keywords": product_kw or "",
                "review_title": review_title or "",
                "review_content": review_content or "",
                "review_emotion_keywords": review_emotion_kw or "",
                "page": int(page) if page else 0,
                "sales_status": sales_status or "",
                "reg_date": str(reg_date.strftime('%Y-%m-%d')) if reg_date else "",
            }

            doc = Document(page_content=content, metadata=metadata)
            documents.append(doc)

        # 2. ë¦¬ë·°ê°€ ì—†ëŠ” ìƒí’ˆë“¤: Productë§Œìœ¼ë¡œ ë¬¸ì„œ ìƒì„± (ì¹´í…Œê³ ë¦¬ ì¡°ì¸ í¬í•¨)
        cursor.execute("""
            SELECT p.isbn, tc.top_category_name, mc.mid_category_name, lc.low_category_name,
                   p.product_name, p.author, p.publisher, p.price, p.rate,
                   p.brief_description, p.detail_description,
                   p.emotion_keyword as product_emotion, p.product_keyword,
                   p.page, p.sales_status, p.reg_date
            FROM product p
            LEFT JOIN product_review pr ON p.isbn = pr.isbn
            LEFT JOIN low_category lc ON p.low_category = lc.low_category
            LEFT JOIN middle_category mc ON lc.mid_category = mc.mid_category
            LEFT JOIN top_category tc ON mc.top_category = tc.top_category
            WHERE p.emotion_keyword IS NOT NULL AND p.product_keyword IS NOT NULL
              AND pr.isbn IS NULL
        """)

        products_without_reviews = cursor.fetchall()

        print(f"ë¦¬ë·° ì—†ëŠ” ìƒí’ˆ ë¬¸ì„œ ìƒì„±: {len(products_without_reviews)}ê°œ")

        for row in products_without_reviews:
            (isbn, top_category_name, mid_category_name, low_category_name,
             name, author, publisher, price, rate,
             brief, detail,
             product_emotion_kw, product_kw,
             page, sales_status, reg_date) = row

            # í‚¤ì›Œë“œ íŒŒì‹±
            emotion_keywords = json.loads(product_emotion_kw) if product_emotion_kw else []
            product_keywords = json.loads(product_kw) if product_kw else []

            # ì™„ì „ ë™ê¸°í™”: page_contentì™€ metadata ì¼ì¹˜ (ë¦¬ë·° ì—†ëŠ” ìƒí’ˆ)
            content = f"""
                ìƒìœ„ ì¹´í…Œê³ ë¦¬: {top_category_name or ''}
                ì¤‘ê°„ ì¹´í…Œê³ ë¦¬: {mid_category_name or ''}
                í•˜ìœ„ ì¹´í…Œê³ ë¦¬: {low_category_name or ''}
                ì œí’ˆëª…: {name}
                ì €ì: {author or ''}
                ì¶œíŒì‚¬: {publisher or ''}
                ê°€ê²©: {price or 0}ì›
                í‰ì : {rate or 0}ì 
                ê°„ë‹¨ ì„¤ëª…: {brief or ''}
                ìƒì„¸ ì„¤ëª…: {detail or ''}
                ìƒí’ˆ ê°ì •: {', '.join(emotion_keywords)}
                ìƒí’ˆ í‚¤ì›Œë“œ: {', '.join(product_keywords)}
                í˜ì´ì§€: {page or 0}í˜ì´ì§€
                íŒë§¤ìƒíƒœ: {sales_status or ''}
                ë“±ë¡ì¼: {reg_date.strftime('%Y-%m-%d') if reg_date else ''}"""

            # ì™„ì „ ë™ê¸°í™”: metadataê°€ page_contentì™€ ì •í™•íˆ ì¼ì¹˜
            metadata = {
                "isbn": isbn,
                "type": "product_only",
                "top_category_name": top_category_name or "",
                "mid_category_name": mid_category_name or "",
                "low_category_name": low_category_name or "",
                "product_name": name,
                "author": author or "",
                "publisher": publisher or "",
                "price": int(price) if price else 0,
                "rate": float(rate) if rate else 0.0,
                "brief_description": brief or "",
                "detail_description": detail or "",
                "product_emotion_keywords": product_emotion_kw or "",
                "product_keywords": product_kw or "",
                "page": int(page) if page else 0,
                "sales_status": sales_status or "",
                "reg_date": str(reg_date.strftime('%Y-%m-%d')) if reg_date else "",
            }

            doc = Document(page_content=content, metadata=metadata)
            documents.append(doc)

        total_docs = len(product_review_pairs) + len(products_without_reviews)
        print(f"ì´ í–¥ìƒëœ ë¬¸ì„œ ìƒì„± ì™„ë£Œ: {total_docs}ê°œ")
        print(f"  - Product+Review ì¡°í•©: {len(product_review_pairs)}ê°œ")
        print(f"  - Productë§Œ: {len(products_without_reviews)}ê°œ")

        return documents

    except Exception as e:
        print(f"í–¥ìƒëœ ë¬¸ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
        return []
    finally:
        cursor.close()
        connection.close()

def create_enhanced_vector_database():
    """í–¥ìƒëœ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±"""
    print("ğŸš€ í–¥ìƒëœ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì„± ì‹œì‘")
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    try:
        # í–¥ìƒëœ Product + Review í†µí•© ë¬¸ì„œ ìƒì„±
        all_documents = create_enhanced_product_review_documents()

        if not all_documents:
            print("âŒ ì„ë² ë”©í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€
        batch_size = 100
        total_batches = (len(all_documents) + batch_size - 1) // batch_size

        print(f"\në°°ì¹˜ í¬ê¸°: {batch_size}, ì´ ë°°ì¹˜ ìˆ˜: {total_batches}")

        for i in range(0, len(all_documents), batch_size):
            batch = all_documents[i:i+batch_size]
            batch_num = (i // batch_size) + 1

            print(f"ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ë¬¸ì„œ)")

            # ë²¡í„°ìŠ¤í† ì–´ì— ë¬¸ì„œ ì¶”ê°€
            vectorstore.add_documents(batch)

            print(f"ë°°ì¹˜ {batch_num} ì™„ë£Œ")

        # ë²¡í„°ìŠ¤í† ì–´ëŠ” ìë™ ì €ì¥ë¨ (persist ë©”ì„œë“œ ë¶ˆí•„ìš”)
        print("\ní–¥ìƒëœ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìë™ ì €ì¥ ì™„ë£Œ")

        print(f"\nâœ… í–¥ìƒëœ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì„± ì™„ë£Œ!")
        print(f"ì €ì¥ ìœ„ì¹˜: {PERSIST_DIRECTORY}")
        print(f"ì´ ì„ë² ë”©ëœ ë¬¸ì„œ ìˆ˜: {len(all_documents)}ê°œ")

    except Exception as e:
        print(f"âŒ í–¥ìƒëœ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì„± ì‹¤íŒ¨: {e}")

    print(f"ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    create_enhanced_vector_database()